version: "3.4"

services:
  fastapi:
    # build: ./app_fastapi/
    image: ghcr.io/blueswen/opentelemetry-apm/fastapi:latest
    ports:
      - "8000:8000"
    environment:
      - TARGET_ONE_SVC=spring-boot:8080
      - TARGET_TWO_SVC=spring-boot:8080
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_METRICS_EXPORTER=none
      - OTEL_SERVICE_NAME=fastapi
    command: "opentelemetry-instrument python main.py"

  spring-boot:
    # build: ./app_springboot/
    image: ghcr.io/blueswen/opentelemetry-apm/springboot:latest
    ports:
      - "8080:8080"
    environment:
      - TARGET_ONE_SVC=fastapi:8000
      - TARGET_TWO_SVC=fastapi:8000
      - OTEL_EXPORTER=otlp_span
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_INSECURE=true
      - OTEL_METRICS_EXPORTER=none
      - OTEL_SERVICE_NAME=spring-boot
    command: "java -javaagent:/opentelemetry-javaagent.jar -jar /app.jar"

  express:
    # build: ./app_express/
    image: ghcr.io/blueswen/opentelemetry-apm/express:latest
    ports:
      - "3001:3001"
    environment:
      - EXPOSE_PORT=3001
      - TARGET_ONE_SVC=fastapi:8000
      - TARGET_TWO_SVC=fastapi:8000
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_SERVICE_NAME=express
    command: "node --require '@opentelemetry/auto-instrumentations-node/register' app.js"

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.100.0
    command:
      - "--config=/conf/config.yaml"
    volumes:
      - ./etc/otel-collector-config.yaml:/conf/config.yaml
    ports:
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP http receiver
      - "8889:8889" # Prometheus metrics exporter
    depends_on:
      - elasticsearch
    restart: on-failure

  apm-server:
    image: docker.elastic.co/apm/apm-server:7.17.25
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8200:8200
    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.25
    environment:
    - bootstrap.memory_lock=true
    - cluster.name=docker-cluster
    - cluster.routing.allocation.disk.threshold_enabled=false
    - discovery.type=single-node
    ulimits:
      memlock:
        hard: -1
        soft: -1
    volumes:
    - ./esdata:/usr/share/elasticsearch/data
    ports:
    - 9200:9200
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.25
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
    - 5601:5601
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status
